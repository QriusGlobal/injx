"""
MkDocs hook to copy extra files to site root after build.
This ensures llms.txt is available at the root URL and generates
per-page markdown and text versions.
"""

import os
import shutil
import re
from pathlib import Path
from mkdocs.config import Config
from bs4 import BeautifulSoup
import html2text


def on_post_build(config: Config, **kwargs) -> None:
    """
    Copy extra files to site directory after build and generate
    markdown/text versions of documentation pages.
    """
    site_dir = Path(config['site_dir'])
    docs_dir = site_dir / 'docs'
    
    # Create docs directory for markdown/text files
    docs_dir.mkdir(exist_ok=True)
    
    # Copy llms.txt to site root (existing functionality)
    src_path = Path('llms.txt')
    dst_path = site_dir / 'llms.txt'
    
    if src_path.exists():
        shutil.copy2(src_path, dst_path)
        print(f"✅ Copied {src_path} to site root")
    else:
        print(f"❌ Warning: {src_path} not found")
    
    # Initialize html2text converter for markdown generation
    h2t = html2text.HTML2Text()
    h2t.ignore_links = False
    h2t.ignore_images = False
    h2t.body_width = 0  # Don't wrap lines
    h2t.unicode_snob = True
    
    # Process all HTML files to generate markdown and text versions
    html_files_processed = 0
    for html_file in site_dir.glob('**/*.html'):
        # Skip files in assets directories
        if any(part in html_file.parts for part in ['assets', 'search', '404.html']):
            continue
        
        try:
            # Read the HTML file
            with open(html_file, 'r', encoding='utf-8') as f:
                html_content = f.read()
            
            # Parse HTML with BeautifulSoup
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # Extract the main content
            content = soup.find('article', class_='md-content__inner')
            if not content:
                content = soup.find('div', class_='md-content')
            if not content:
                continue  # Skip if no content found
            
            # Remove navigation elements, buttons, etc.
            for element in content.find_all(['nav', 'button', 'style', 'script']):
                element.decompose()
            
            # Get the page title
            title = soup.find('title')
            title_text = title.get_text(strip=True) if title else 'Documentation'
            
            # Generate clean HTML for conversion
            clean_html = str(content)
            
            # Generate markdown version
            markdown_content = h2t.handle(clean_html)
            markdown_content = f"# {title_text}\n\n{markdown_content}"
            
            # Generate plain text version
            text_content = content.get_text(separator='\n', strip=True)
            text_content = f"{title_text}\n\n{text_content}"
            
            # Clean up excessive whitespace
            markdown_content = re.sub(r'\n{3,}', '\n\n', markdown_content)
            text_content = re.sub(r'\n{3,}', '\n\n', text_content)
            
            # Determine output paths
            relative_path = html_file.relative_to(site_dir)
            base_name = relative_path.stem
            
            # Special handling for index.html
            if base_name == 'index':
                parent_dir = relative_path.parent
                if parent_dir == Path('.'):
                    base_name = 'index'
                else:
                    base_name = parent_dir.name
            
            # Create markdown and text file paths
            md_path = docs_dir / f"{base_name}.md"
            txt_path = docs_dir / f"{base_name}.txt"
            
            # Write markdown file
            with open(md_path, 'w', encoding='utf-8') as f:
                f.write(markdown_content.strip())
            
            # Write text file
            with open(txt_path, 'w', encoding='utf-8') as f:
                f.write(text_content.strip())
            
            html_files_processed += 1
            
        except Exception as e:
            print(f"⚠️  Warning: Failed to process {html_file}: {e}")
            continue
    
    print(f"✅ Generated markdown and text versions for {html_files_processed} pages")
    
    # Also check if llms-full.txt was generated by the plugin
    llms_full = site_dir / 'llms-full.txt'
    if llms_full.exists():
        print(f"✅ llms-full.txt generated by mkdocs-llmstxt plugin")
    else:
        print(f"ℹ️  Note: llms-full.txt not found (will be generated by plugin)")